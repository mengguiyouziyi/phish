#!/usr/bin/env python3
"""
æ™ºèƒ½æƒé‡ç­–ç•¥ï¼Œæ ¹æ®URLå¤æ‚åº¦è°ƒæ•´æ¨¡å‹æƒé‡
"""

import re
import sys
sys.path.append('.')

from phishguard_v1.models.inference import InferencePipeline

def analyze_url_complexity(url):
    """åˆ†æURLå¤æ‚åº¦"""
    complexity_score = 0

    # é•¿åº¦å¾—åˆ†
    if len(url) > 50:
        complexity_score += 1
    if len(url) > 100:
        complexity_score += 1

    # è·¯å¾„æ·±åº¦
    path_depth = url.count('/') - 2  # å‡å» http:// çš„ä¸¤ä¸ªæ–œæ 
    if path_depth > 2:
        complexity_score += 1
    if path_depth > 4:
        complexity_score += 1

    # æŸ¥è¯¢å‚æ•°
    if '?' in url:
        complexity_score += 1
        query_params = url.split('?')[1]
        param_count = query_params.count('&') + 1
        if param_count > 2:
            complexity_score += 1

    # ç‰¹æ®Šå­—ç¬¦
    special_chars = sum(1 for c in url if c in ['%', '&', '=', '+', ';'])
    if special_chars > 2:
        complexity_score += 1

    # æ–‡ä»¶æ‰©å±•å
    if any(ext in url.lower() for ext in ['.php', '.html', '.htm', '.asp', '.aspx', '.jsp']):
        complexity_score += 0.5

    # ID-like patterns
    id_patterns = re.findall(r'/[a-zA-Z0-9]{8,}/', url)
    if id_patterns:
        complexity_score += 1

    return complexity_score

def get_dynamic_weights(url, url_prob, fusion_prob):
    """æ ¹æ®URLå¤æ‚åº¦å’Œæ¨¡å‹ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´æƒé‡"""
    complexity = analyze_url_complexity(url)

    # åŸºç¡€æƒé‡
    base_url_weight = 0.6
    base_fusion_weight = 0.4

    # æ ¹æ®å¤æ‚åº¦è°ƒæ•´
    if complexity >= 3:
        # é«˜å¤æ‚åº¦URLï¼ŒFusionDNNæƒé‡æ›´é«˜
        url_weight = base_url_weight - 0.2
        fusion_weight = base_fusion_weight + 0.2
    elif complexity >= 2:
        # ä¸­ç­‰å¤æ‚åº¦ï¼Œç¨å¾®è°ƒæ•´
        url_weight = base_url_weight - 0.1
        fusion_weight = base_fusion_weight + 0.1
    else:
        # ä½å¤æ‚åº¦ï¼Œä½¿ç”¨åŸºç¡€æƒé‡
        url_weight = base_url_weight
        fusion_weight = base_fusion_weight

    # æ ¹æ®æ¨¡å‹ç½®ä¿¡åº¦è°ƒæ•´
    # å¦‚æœURLæ¨¡å‹ç½®ä¿¡åº¦å¾ˆä½ï¼Œé™ä½å…¶æƒé‡
    if url_prob < 0.1:
        url_weight *= 0.7
        fusion_weight *= 1.3

    # å¦‚æœFusionDNNç½®ä¿¡åº¦å¾ˆé«˜ï¼Œé€‚å½“æé«˜æƒé‡
    if fusion_prob > 0.95 or fusion_prob < 0.05:
        fusion_weight *= 1.1
        url_weight *= 0.9

    # å½’ä¸€åŒ–æƒé‡
    total_weight = url_weight + fusion_weight
    url_weight /= total_weight
    fusion_weight /= total_weight

    return {"url": url_weight, "fusion": fusion_weight}

def test_smart_weight_strategy():
    """æµ‹è¯•æ™ºèƒ½æƒé‡ç­–ç•¥"""
    print("ğŸ” æµ‹è¯•æ™ºèƒ½æƒé‡ç­–ç•¥...")

    pipe = InferencePipeline(fusion_ckpt_path="artifacts/fusion_balanced_v2.pt", enable_fusion=True)

    # æµ‹è¯•URLs
    test_urls = [
        "https://www.baidu.com",
        "https://www.baidu.com/index.php",
        "https://www.baidu.com/s?wd=test",
        "https://www.baidu.com/img/bd_logo1.png",
        "https://www.google.com/search?q=test",
        "https://www.youtube.com/watch?v=dQw4w9WgXcQ",
        "http://verify-paypal-account.com",
        "http://apple-account-verify.com"
    ]

    print(f"{'URL':<50} {'å¤æ‚åº¦':<6} {'URLæƒé‡':<8} {'Fusionæƒé‡':<10} {'URLæ¨¡å‹':<10} {'FusionDNN':<10} {'æœ€ç»ˆ':<10} {'ç»“æœ':<8}")
    print("-" * 130)

    for url in test_urls:
        features = {
            "request_url": url,
            "final_url": url,
            "status_code": 200,
            "content_type": "text/html",
            "bytes": 1024,
            "url_feats": {
                "url_len": len(url),
                "host_len": len(url.split('//')[-1].split('/')[0]),
                "path_len": len('/'.join(url.split('/')[3:])),
                "num_digits": sum(c.isdigit() for c in url),
                "num_letters": sum(c.isalpha() for c in url),
                "num_specials": sum(not c.isalnum() for c in url),
                "num_dots": url.count('.'),
                "num_hyphen": url.count('-'),
                "num_slash": url.count('/'),
                "num_qm": url.count('?'),
                "num_at": url.count('@'),
                "num_pct": url.count('%'),
                "has_ip": False,
                "subdomain_depth": url.split('//')[-1].split('/')[0].count('.'),
                "tld_suspicious": 0,
                "has_punycode": 0,
                "scheme_https": 1 if url.startswith('https') else 0,
                "query_len": len(url.split('?')[-1]) if '?' in url else 0,
                "fragment_len": len(url.split('#')[-1]) if '#' in url else 0
            }
        }

        # è·å–æ¨¡å‹é¢„æµ‹
        result = pipe.predict(features)
        url_prob = result['url_prob']
        fusion_prob = result['fusion_prob']

        # è®¡ç®—åŠ¨æ€æƒé‡
        weights = get_dynamic_weights(url, url_prob, fusion_prob)

        # é‡æ–°è®¡ç®—æœ€ç»ˆæ¦‚ç‡
        final_prob = weights["url"] * url_prob + weights["fusion"] * fusion_prob
        label = 'è‰¯æ€§' if final_prob >= 0.5 else 'é’“é±¼'

        complexity = analyze_url_complexity(url)

        print(f"{url:<50} {complexity:<6} {weights['url']:<8.3f} {weights['fusion']:<10.3f} {url_prob:<10.4f} {fusion_prob:<10.4f} {final_prob:<10.4f} {label:<8}")

if __name__ == "__main__":
    test_smart_weight_strategy()