#!/usr/bin/env python3
"""
æµ‹è¯•å¹³è¡¡æ¨¡åž‹å¯¹ç™¾åº¦ç­‰ä¸­å›½ç½‘ç«™çš„è¡¨çŽ°
"""

import torch
import torch.nn as nn
import numpy as np
import sys
sys.path.append('.')

from phishguard_v1.models.fusion_model import FusionDNN

def test_balanced_model():
    """æµ‹è¯•å¹³è¡¡æ¨¡åž‹"""
    print("ðŸ§ª æµ‹è¯•å¹³è¡¡èžåˆæ¨¡åž‹ v2...")

    # æµ‹è¯•URLåˆ—è¡¨
    test_urls = [
        # ä¸­å›½è‰¯æ€§ç½‘ç«™
        'https://www.baidu.com',
        'https://www.taobao.com',
        'https://www.qq.com',
        'https://www.jd.com',
        'https://www.zhihu.com',
        # å›½é™…è‰¯æ€§ç½‘ç«™
        'https://www.google.com',
        'https://www.github.com',
        'https://www.wikipedia.org',
        # é’“é±¼ç½‘ç«™æ ·ä¾‹
        'http://verify-paypal-account.com',
        'http://apple-security-update.info',
        'http://microsoft-login-alert.com',
    ]

    # åŠ è½½æ¨¡åž‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    ckpt = torch.load('artifacts/fusion_balanced_v2.pt', map_location='cpu', weights_only=False)

    model = FusionDNN(num_features=ckpt['input_features']).to(device)
    model.load_state_dict(ckpt['model_state_dict'])
    model.eval()

    # å‡†å¤‡æ ‡å‡†åŒ–å™¨
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.mean_ = np.array(ckpt['scaler_mean'])
    scaler.scale_ = np.array(ckpt['scaler_scale'])

    feature_names = ckpt['feature_names']

    def extract_url_features(url):
        """æå–URLç‰¹å¾"""
        from urllib.parse import urlparse
        import re

        parsed = urlparse(url)
        hostname = parsed.hostname or ""
        path = parsed.path or ""
        query = parsed.query or ""
        fragment = parsed.fragment or ""

        features = {}

        features['url_len'] = len(url)
        features['host_len'] = len(hostname)
        features['path_len'] = len(path)
        features['query_len'] = len(query)
        features['fragment_len'] = len(fragment)

        features['num_digits'] = len(re.findall(r'\d', url))
        features['num_letters'] = len(re.findall(r'[a-zA-Z]', url))
        features['num_specials'] = len(re.findall(r'[^\w\d]', url))
        features['num_dots'] = url.count('.')
        features['num_hyphen'] = url.count('-')
        features['num_slash'] = url.count('/')
        features['num_qm'] = url.count('?')
        features['num_at'] = url.count('@')
        features['num_pct'] = url.count('%')

        features['has_ip'] = 1 if re.match(r'\d+\.\d+\.\d+\.\d+', hostname) else 0
        features['subdomain_depth'] = len(hostname.split('.')) - 2 if hostname.count('.') > 1 else 0
        features['tld_suspicious'] = 1 if hostname.split('.')[-1] in ['tk', 'ml', 'ga', 'cf', 'top'] else 0
        features['has_punycode'] = 1 if 'xn--' in hostname else 0
        features['scheme_https'] = 1 if parsed.scheme == 'https' else 0

        features['status_code'] = 200
        features['bytes'] = 1024

        return features

    print(f"\nðŸ“Š æµ‹è¯•ç»“æžœ:")
    print("-" * 80)

    for url in test_urls:
        # æå–ç‰¹å¾
        features = extract_url_features(url)
        X = np.array([[features[feat] for feat in feature_names]])
        X_scaled = scaler.transform(X)

        # é¢„æµ‹
        with torch.no_grad():
            X_tensor = torch.FloatTensor(X_scaled).to(device)
            outputs = model(X_tensor)
            probs = torch.softmax(outputs, dim=1)

            benign_prob = probs[0][0].item()
            phishing_prob = probs[0][1].item()

            prediction = "è‰¯æ€§" if benign_prob > phishing_prob else "é’“é±¼"
            confidence = max(benign_prob, phishing_prob)

            print(f"{url}")
            print(f"  é¢„æµ‹: {prediction} (ç½®ä¿¡åº¦: {confidence:.2%})")
            print(f"  è‰¯æ€§æ¦‚çŽ‡: {benign_prob:.4f} ({benign_prob*100:.2f}%)")
            print(f"  é’“é±¼æ¦‚çŽ‡: {phishing_prob:.4f} ({phishing_prob*100:.2f}%)")
            print()

if __name__ == "__main__":
    test_balanced_model()