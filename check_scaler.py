#!/usr/bin/env python3
"""
æ£€æŸ¥æ ‡å‡†åŒ–å™¨å‚æ•°é—®é¢˜
"""

import torch
import numpy as np
import sys
sys.path.append('.')

def check_model_scaler():
    """æ£€æŸ¥æ¨¡å‹çš„æ ‡å‡†åŒ–å™¨å‚æ•°"""
    print("ğŸ” æ£€æŸ¥æ¨¡å‹æ ‡å‡†åŒ–å™¨å‚æ•°...")

    # åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
    ckpt = torch.load('artifacts/fusion_balanced_v2.pt', map_location='cpu', weights_only=False)

    print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"  ç‰¹å¾æ•°é‡: {ckpt.get('input_features', 'N/A')}")
    print(f"  ç‰¹å¾åç§°: {ckpt.get('feature_names', [])}")
    print(f"  æ ‡å‡†åŒ–å™¨å‡å€¼: {ckpt.get('scaler_mean', [])}")
    print(f"  æ ‡å‡†åŒ–å™¨æ ‡å‡†å·®: {ckpt.get('scaler_scale', [])}")

    # æ£€æŸ¥ç™¾åº¦ç‰¹å¾çš„æ ‡å‡†åŒ–
    baidu_features = [21.0, 13.0, 1.0, 0.0, 16.0, 5.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 200.0, 227.0]

    print(f"\nğŸ“Š ç™¾åº¦ç‰¹å¾æ ‡å‡†åŒ–æ£€æŸ¥:")
    print(f"  åŸå§‹ç‰¹å¾: {baidu_features}")

    scaler_mean = np.array(ckpt.get('scaler_mean', [0.0] * len(baidu_features)))
    scaler_scale = np.array(ckpt.get('scaler_scale', [1.0] * len(baidu_features)))

    print(f"  æ ‡å‡†åŒ–å™¨å‡å€¼: {scaler_mean}")
    print(f"  æ ‡å‡†åŒ–å™¨æ ‡å‡†å·®: {scaler_scale}")

    # é€ä¸ªç‰¹å¾æ ‡å‡†åŒ–
    normalized_features = []
    for i, (feat, mean, scale) in enumerate(zip(baidu_features, scaler_mean, scaler_scale)):
        normalized = (feat - mean) / scale
        normalized_features.append(normalized)
        if abs(normalized) > 10:  # æ£€æŸ¥æç«¯å€¼
            print(f"  âš ï¸  ç‰¹å¾ {i} ({ckpt.get('feature_names', [f'feat_{i}'])[i]}): {feat} -> {normalized:.2f}")

    print(f"  æ ‡å‡†åŒ–åç‰¹å¾: {normalized_features}")

if __name__ == "__main__":
    check_model_scaler()